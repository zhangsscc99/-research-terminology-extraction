_OD AlphaGo_NR

-{H|zh-cn:_PU 蒙特_NN 卡洛_NN ;_PU zh_NN -_PU tw_NN :_PU 蒙地_NN 卡羅_NN }_PU -_PU
-{H|zh-cn:_PU 账号_NN ;_PU zh_NN -_PU tw_NN :_PU 帳號_NN }_PU -_PU
-{H|zh-cn:_PU 身份_NN ;_PU zh_NN -_PU tw_NN :_PU 身分_NN }_PU -_PU
（_PU “_PU Go_NN ”_PU 为日文_NN “_PU 碁_NN ”_PU 字_NN 发音_NN 转写_NN ，_PU 是围棋_NN 的_DEC 西方名称_NN ）_PU ，_PU 直译_NN 为_NN 阿尔_NN 法围棋_NN ，_PU 亦_AD 被_P 音译_VV 为_VC 阿尔法狗_NN 、_PU 阿法狗_NN 、_PU 阿发狗等_NN ，_PU 是於_NN 2014_CD 年_CD 开始_NN 由_P 英国_NR 伦敦_NN GoogleDeepMind_NR 开发_NN 的_DEC 人工_NN 智能_NN 圍棋_VV 軟體_NN 。_PU 2017年_NT ，_PU 關於_NN AlphaGo_NN 的_DEC 電影紀_NN 錄片_NN 《_PU AlphaGo_NN 世紀_NN 對決_NN 》_PU 正式_NN 上映_VV 。_PU

專業_NN 術語上_NN 來_AD 說_VA ，_PU AlphaGo_NN 的_DEC 做法_NN 是_VC 使用_VV 了_AS 蒙特卡_NN 洛_NN 树搜索_NN 與_NN 兩_CD 個深度神_NN 經_NN 網路相_NN 結合_VV 的_DEC 方法_NN ，_PU 一_CD 個_NN 是_VC 以借_NN 助估值_NN 网络_NN （_PU valuenetwork_NR ）_PU 來評估_NR 大量_CD 的_DEG 選_NN 點_CD ，_PU 一_CD 个_M 是借助_NN 走棋_NN 网络_NN （_PU policynetwork_NR ）_PU 來選擇_NR 落子_NN ，_PU 并_AD 使用_VV 强_NN 化学习_NN 进一步_JJ 改善它_NN 。_PU 在_P 這種設_NN 計下_VV ，_PU 電_BA 腦_NN 可_VV 以_NN 結合樹狀圖_VV 的_DEC 長遠推斷_NN ，_PU 又_CC 可_VV 像_LB 人類_VV 的_DEC 大腦_CD 一_CD 樣_NN 自發學_NN 習_NN 進行_VV 直_CD 覺訓練_NN ，_PU 以提高_NN 下_NN 棋實力_NN 。_PU

一_CD 般认为_NN ，_PU 电脑要_NN 在_VV 围棋_NN 中_LC 取胜比在_VV 国_NN 际象棋_NN 等_ETC 游戏中_NN 取_VV 胜要_JJ 困难得多_NN ，_PU 因_NN 为围棋_NN 的_DEG 下棋_NN 點_OD 極_NN 多_CD ，_PU 分_NN 支因子_NN 遠多于_VV 其_NN 他游戏_NN ，_PU 而_CC 且每次_NN 落子_NN 對情勢_NN 的_DEC 好壞飄忽_NN 不_AD 定_VA ，_PU 诸如_NN 暴力_NN 搜尋法_NN 、_PU Alpha_NN -_PU beta_NN 剪枝_NN 、_PU 启发式_JJ 搜索_NN 的_DEC 传统人_NN 工智能_NN 方法_NN 在_VV 围棋_NN 中_LC 很_AD 难奏效_NN 。_PU 在_P 1997_CD 年_PU IBM_NN 的_DEC 电脑_NN 「_PU 深_NN 蓝_OD 」_PU 击败_NR 俄籍_NN 世界_NN 国际象_NN 棋冠军_NN 加里_VV ·_PU 卡斯_NN 帕罗夫_NN 之后_LC ，_PU 经过_VV 18年_CD 的_DEG 发展_NN ，_PU 棋力_NN 最_AD 高_VA 的_DEC 人工智_NN 能围棋_NN 程序才_NN 大_NN 约_AD 达到_VV 业余_NN 5_CC 段围棋_NN 棋手_VV 的_DEC 水準_NN ，_PU 且_AD 在_P 不让子_NN 的_DEC 情况下_NN ，_PU 仍无_NN 法击_NN 败职_NN 业棋手_NN 。_PU 2012年_NT ，_PU 在_P 4_OD 台_M PC_NN 上_NN 运行_NN 的_DEC Zen_NN 程序_NN 在_P 让_NN 5_OD 子_NN 和让_NN 4_CD 子_NN 的_DEC 情况_NN 下_NN 两_CD 次_M 击败日_NN 籍_NN 九_OD 段_NN 棋士_NN 武_NN 宫正树_NN 。_PU 2013_CD 年_M ，_PU 在_P 让_NN 4_OD 子_NN 的_DEG 情况_NN 下_NN 击_CS 败日籍_NN 九_OD 段_NN 棋士石_NN 田_NN 芳夫_NN ，_PU 這樣_NN 偶爾_NN 出現_VV 的_DEC 戰果就_NN 已_AD 經_AD 是_VC 難得_VV 的_DEC 結果了_NN 。_PU

AlphaGo_NN 的_DEC 研究計劃_NN 於_P 2014_CD 年啟動_NN ，_PU 此後和_NN 之前_NN 的_DEC 围棋_NN 程序_NN 相比表_NN 现出_VV 显著_NN 提升_NN 。_PU 在_AD 和_P CrazyStone_NN 和_NN Zen_NN 等_ETC 其_PN 他围棋_NN 程序的_NN 500_CD 局比赛_NN 中_LC ，_PU 单机版_NN AlphaGo_NN （_PU 运行于_VV 一_CD 台_M 电脑上_NN ）_PU 仅输一局_VV 。_PU 而_CC 在_P 其_PN 后_NN 的_DEG 对局中_NN ，_PU 分布式版_JJ AlphaGo_NN （_PU 以分散式_JJ 運算_NN 运行于_VV 多台_NN 电脑上_NN ）_PU 在_VV 500_CD 局比赛_NN 中_LC 全部_NN 获胜_VV ，_PU 且對抗_NN 運行在_NN 單機上_NN 的_DEC AlphaGo_NN 约_AD 有_VE 77%_CD 的_DEG 勝率_NN 。_PU 2015_CD 年_PU 10_CD 月的_M 分散式_NN 運算_NN 版本_NN AlphaGo_NN 使用了_NN 1_CD ,_PU 202_CD 块_M CPU_NN 及_NN 176_CD 块_M GPU_NN 。_PU


AlphaGo_NN 在_AD 沒有_VV 人類對_NN 手後_VV ，_PU AlphaGo_NN 之父杰米_NN 斯_NN ·_PU 哈萨_NN 比斯_NN 宣布_VV AlphaGo_NN 退役_NN 。_PU 而從_NN 業餘_NN 棋士_VV 的_DEC 水平到_NN 世界第_NN 一，A_CD lphaGo_NR 的_DEC 棋力取_NN 得這樣_NN 的_DEC 進步_NN ，_PU 僅僅_NR 花了_NN -_PU {zh-cn:两;zh-tw:二;}_PU -_PU 年左右_NN 。_PU

最終_JJ 版本_NN AlphaZero_NN 擁有_VV 更加強大_VV 的_DEC 學習_NN 能力_NN ，_PU 可_VV 自我學習_NR ，_PU 在21天_NR 達到_NN 勝過_NN 中國_NN 顶尖_NN 棋手_NN 柯潔_VV 的_DEC AlphaGoMaster_NR 的_DEC 水平_NN 。_PU

2014_CD 年起_NN ，_PU AlphaGo_NN 以英_NN 国棋友_NN deepmind_NN 的_DEC 名义_NN 开始_NN 在_P 弈城围_NN 棋网上_NN 对弈_NN 。_PU deepmind_NN 在_P 2014_CD 年_CC 4月_CD 到_P 2015年_CD 9月_NT 长达_NN 1_CD 年半_VV 的_DEC 时间里_NN ，_PU 维持_VV 在_P 7D_CD 到_CC 8D_CD 之间_NN ，_PU 总_AD 共下_VV 了_AS 300_CD 多盘棋_NN 。_PU 2015年_CD 9月_NT 16日_NT 首次升上_NT 9D_CD ，_PU 之后_VV 在_P AlphaGo_NN 与樊麾对_NN 弈_AD 前后_VV 的_DEC 三_CD 个_M 月内未_NN 进行_VV 网络_NN 对弈_NN 。_PU 2015年_NT 12月到_NT 2016年_NT 2月_NT ，_PU deepmind_NR 一_DEC 共下了_NR 136_CD 盘_M ，_PU 基本在_NR 9D_CD 水平_NN 。_PU 其中_NN 和职业_NN 棋_AD 手_VA 的_DEC 多次对局_NN 互有_VV 胜负_NN 。_PU

黄士杰在_NN AlphaGo_NN 与李世乭_NN 九段比_NN 赛前_NT 曾否认_NN deepmind_NN 是_VC AlphaGo_NN 的_DEC 测试_NN 账号_NN ，_PU 但是_CC 在_VV AlphaGo_NN 与李_NN 世石_NN 比赛之_NN 后_LC ，_PU DeepMind_NN 创始人_NN 哈_NN 萨比_NN 斯承认_NN AlphaGo_NN 曾经_NN 使用_NN deepmind_NN 账号_NN 进行_VV 过测试_NN 。_PU

2016年_NT 12月_NT 16日_NT ，_PU 在_P AlphaGo_NN 以_NN Master_NN 身份_NN 登录弈_NN 城围_NN 棋网_NN 之前_VV ，_PU 黄_BA 士杰_NN 要求_NN 删_NN 除_NN deepmind_NN 账号_NN 。_PU 现在_NT deepmind_NN 的_DEC 战绩和_NN 棋谱已_NN 经无_NN 法_NN 查阅_VV 。_PU

2015年_NT 10月_NT ，_PU 分布式版_JJ AlphaGo_NN 分先以_VV 5_CD :_PU 0_CD 击_M 败了欧_NN 洲围棋_NN 冠_NN 军華_NN 裔法籍_NN 职业_NN 棋士樊麾_NN 二_OD 段_NN 。_PU 这是_NN 电脑_NN 围棋_NN 程序第_NN 一_OD 次_NN 在_VV 十九_CD 路_BA 棋盘_NN 且_LC 分先_VV 的_DEC 情況下_NN 击_CD 败职_NN 业围棋_NN 棋_NN 手_NN 。_PU 新_NN 闻_NN 发布_VV 被_LB 推迟_VV 到_P 2016年_CD 1月_NT 27日_NT ，_PU 和_P 描述_JJ 算法_NN 的_DEC 论文_NN 一起_AD 发布_VV ，_PU 而_CC 论文发表_NN 在_NN 《_PU 自然_NN 》_PU 上_NN 。_PU

2016年_NT 3月_NT ，_PU AlphaGo_NN 挑战_NN 世界_NN 冠军韩_NN 国职业_NN 棋士_NN 李世乭_NN （_PU ）_PU 九_OD 段_M 。_PU AlphaGo_NN 使用谷_NN 歌位于_VV 美国的_NR 云计算_NN 服务器_NN ，_PU 并_AD 通过_P 光缆网_NN 络_AD 连接_VV 到_VV 韩国_NR 。_PU 比賽的_NR 地_NN 點_OD 為_M 韩国首爾_NN 四_OD 季_NN 酒店_NN ；_PU 赛制为_VV 五_CD 番棋_M ，_PU 分別於_NN 2016年_CD 3月9日_NT 、_PU 10_CD 日_NN 、_PU 12_CD 日_NN 、_PU 13_CD 日和_M 15_CD 日_NN 进行_VV ；_PU 规则_NN 为_VC 中国_NR 围棋规_NN 则_NN ，_PU 黑棋贴_NN 3_CD 又_CC 3/_CD 4子_NN ；_PU 用时_NN 为_VC 每方_NN 2_CD 小时_VV ，_PU 3_OD 次_NN 1_OD 分钟_M 读秒_NN 。_PU DeepMind_NN 团队_VV 在_P YouTube_NN 上_NN 全球直播_NN 并_AD 由_P 美籍職業_NR 棋士邁_NN 克_NN ·_PU 雷蒙_NN （_PU MichaelRedmond_NR ）_PU 九段擔任英_NR 语解说_NN ，_PU 而中国_NN 大_NN 陆_CD 很_AD 多_CD 视频_NN 网站_NN 也_AD 采用_VV YouTube_NN 的_DEC 直播_NN 信号_NN 进行_VV 直播_NN ，_PU 并加_VV 上_NN 自己_NN 的_DEC 解说_NN 。_PU DeepMind_NN 團_NN 隊成_VV 員台湾_NN 業_NN 余_VC 6_CD 段圍棋_NN 棋_NN 士_NN 黃士傑_NN 博_NN 士代表_NN AlphaGo_NN 在_NN 棋盘_NN 上_NN 落子_NN 。_PU

比赛_NN 獲勝者_NN 將獲得_NN 100萬_CD 美元_NN 的_DEC 獎金_NN 。_PU 如果_NN AlphaGo_NN 獲勝_NN ，_PU 獎金將_NN 捐贈_NN 給围棋_NN 组织_NN 和慈善_NN 機構_VV ，_PU 包括_VV 联合_NN 国兒童_NN 基金會_NN 。_PU 李世_NN 乭有_VV 15万_CD 美元_NN 的_DEC 出场費_NN ，_PU 且每贏_NN 一_CD 盘_NN 棋_AD 会_VV 再得_VV 2万_CD 美元_NN 的_DEC 奖金_NN 。_PU

2016年_NT 3月9日_NN 、_PU 10_CD 日和_NN 12_CD 日的_M 三_CD 局_NN 对战均_NN 为_VC AlphaGo_NN 獲勝_NN ，_PU 而_CC 13日_NT 的_DEG 对战则_NN 为_VC 李世乭_NN 获胜_VV ，_PU 15日_NT 的_DEG 最終局_NN 則又是_NN AlphaGo_NN 獲勝_NN 。_PU 因此對弈_NN 結果_NN 为_VC AlphaGo4_NN :_PU 1_CD 战_M 胜了李_NN 世乭_VV 。_PU 这次_NN 比赛在_NN 网络_NN 上引发_NN 了_LB 人_NN 们_NN 对此次比_NN 赛和人_NN 工智能_NN 的_DEC 广泛讨论_NN 。_PU

2016年_NT 11月_NT 7日_NT ，_PU 樊麾在_NN 微博上_NN 表示_VV AlphaGo_NN 的_DEC 实力大_NN 增_NN ，_PU 将_BA 在_VV 2017_CD 年初_NN 进行_VV 更多比赛_NN 。_PU DeepMind_NN 创办人杰_NN 米_NN 斯_VC ·_PU 哈萨比_NN 斯随后证_VV 实此_NN 消息_NN 。_PU 然而并_NN 未_AD 公布_VV 细节_NN 。_PU

2016年_NT 12月_NT 29日_NT 晚上七點起_NT ，_PU 中國的_NR 弈城_NN 围棋_NN 网出_NN 現疑似人_NN 工智_NN 能围_NN 棋软件_NN 的_DEC 围棋高_NN 手_NN ，_PU 帳號名為_NN “_PU Magister_NN ”_PU （_PU 中国_NR 大陆_CD 客户端_NN 显示为_NN “_PU Magist”_NN ）_PU ，_PU 後又改名_NN 為_NN “_PU Master_NN ”_PU 。_PU 2017年_CD 1月1日_NT 晚上十一点_NT Master_NN 转_NN 战至_NN 騰訊_NN 旗下_NN 的_DEC 野狐_NN 围棋网_NN 。_PU Master_NN 以其_NN 空前_VV 的_DEC 实力_NN 轰动_VV 了围棋界_NN 。_PU 它以每天_NN 十_CD 盘_NN 的_DEG 速度_NN 在_VV 弈城_NR 、_PU 野狐等_NN 网络_NN 围棋_NN 对战_NN 平台_NN 挑战中_NN 韩_CD 日台_VV 的_DEC 顶尖高手_NN ，_PU 到_P 2017年_NT 1月4日公测_NN 结束_NN 为止_NN 60_CD 战全胜_NN ，_PU 其中_NN 弈城_NN 30_CD 战野狐_NN 30_OD 战_M ，_PU 战胜了_NR 柯洁_NN 、_PU 朴廷桓_NN 、_PU 井山裕太_NN 、_PU 柁嘉熹_NN 、_PU 芈昱廷_NN 、_PU 时越_NN 、_PU 陈耀烨_NN 、_PU 李钦诚_NN 、_PU 古力_NN 、_PU 常昊_NN 、_PU 唐韦星_NN 、_PU 范廷钰_NN 、_PU 周睿羊_NN 、_PU 江维杰_NN 、_PU 党毅飞_NN 、_PU 周俊勳_NN 、_PU 金志锡_NN 、_PU 姜东润_NN 、_PU 朴永训_NN 、_PU 元晟溱_NN 等_ETC 世界_NN 冠军棋_NN 手_NN ，_PU 连笑_NN 、_PU 檀啸_NN 、_PU 孟泰龄_NN 、_PU 黄云嵩_NN 、_PU 杨鼎新_NN 、_PU 辜梓豪_NN 、_PU 申真谞_NN 、_PU 赵汉乘_NN 、_PU 安成浚_NN 等_ETC 中国_NR 或韩国_NN 国内冠_NN 军或者_NN 世界_NN 亚军棋_NN 手_NN ，_PU 以及_NN 世界_NN 女子第_NN 一_ETC 人_NN 於_NN 之莹_NN 。_PU 期間_NN 古力曾_NN 懸賞_NN 人民_NN 幣_NN 10萬_CD 元給第_NN 1_OD 位_NN 戰勝_NN Master_NN 者_NN 。_PU

Master_NN 所_MSP 進行_VV 的_DEC 60_CD 战基_NN 本都是_NN 3_OD 次_CC 20_CD 秒或30秒_M 读秒的_NN 快棋_NN ，_PU 僅在與_NR 聶衛_NN 平_NN 交戰時_NN 考虑_VV 到_VV 聂老年_NN 纪_AD 大_VA 而_MSP 延長為_VV 1_CD 分鐘_M ，_PU 并且_CC 賽後還以_NR 繁體_NN 中_LC 文打上_VV 「_PU 謝_BA 謝聶老師_NN 」_PU 5_CD 字_M 。_PU 該帳號於_NN 59_CD 連勝後_NN 称_NN 「_PU 我是_NN AlphaGo_NN 的_DEC 黃博士_NN 」_PU ，_PU 表明_NN Master_NN 就是_NN AlphaGo_NN ，_PU 代為_VV 落子_NN 的_NN 是_VC AlphaGo_NN 團隊_NN 成员來_NN 自台灣_NN 的_DEC 黄士傑_NN 博士_VV ；_PU DeepMind_NN 创始人_NN 之一_NN 杰_NN 米_AD 斯_VA ·_PU 哈萨比_NN 斯于_NN 比赛_NN 结束_VV 后_VV 在_P 其推_NN 特上_NN 表示_VV “_PU 我们_PN 很期待在_JJ 今后_NN （_PU 2017年_NT ）_PU 与围棋_NN 组织_NN 和专_NN 家合作_NN ，_PU 在_P 官方比_NN 赛_NN 中下_JJ 几盘慢_NN 棋_NN ”_PU ，_PU 黃士傑與_NN 樊_NN 麾_NN 也分別在_NN Facebook_NN 與微博_NN 上_NN 發_NN 表官_NN 方中文_NN 譯文_VV ，_PU 表示_VV 對各_NN 國頂_NN 尖棋手參_NN 與_ETC AlphaGo_NN 的_DEC 網路_NN 公_NN 測_NN 的_DEC 感謝_NN 。_PU 2017_CD 年_PU 1月_CD 5_CD 日_NN 晚_LC ，_PU 中国_NR 中央_NN 电视台_NN 《_PU 新_NN 闻联_VV 播_NN 》_PU 以_NN “_PU 人_NN 工智能_NN ‘_PU 阿尔法狗_NN ’_PU 横扫围棋_NN 高_JJ 手_NN ”_PU 为题_NN 报道_VV 了_AS 最近_JJ 火爆_NN 的_DEC Master_NN 网络_NN 快棋_NN 60_CD 连胜人_NN 类_NN 高手_NN 的_DEC 事件_NN ，_PU 新闻还_NR 提到_NN ，_PU “_PU 这次_NN 事件_NN 为_VC 接下来_NN 的_DEC 人机_NN 对决_NN 做出_VV 了_AS 很_AD 好_VA 的_DEC 预热_NN ”_PU 。_PU

因为人_NR 类棋手_NN 在_VV 慢棋_NN 中_LC 有更久_VV 的_DEC 思考_NN 时间_NN ，_PU 所以_AD 虽然_CS AlphaGo_NN 在_NN 网络_NN 快棋_NN 中_AD 大_VA 获全胜_NN ，_PU 但仍_NN 不能断_NN 言其_VV 在_VV 官方慢_NN 棋比_NN 赛中_NN 是_VC 否也会有_NR 如此_NN 出色_VV 的_DEC 表现_NN 。_PU 不_AD 过_VV 职业棋_NN 手_NN 们对AlphaGo不同于人类的独特棋风以及它高超的_PU 棋力_NN 印象_NN 深刻_VA ，_PU 柯洁在其_NN 微博中_NN 表示_VV “_PU 感谢_NN Alphago_NN 最新版_JJ 给我们棋_NN 界带来_NN 的_DEC 震撼_NN ”_PU ，_PU 并_NR “_PU 略有_NR 遗憾_NN ”_PU 地称_NN “_PU 若不_NN 是_VC 住院_NR ，_PU 我将用_NR 上那_NN 准备_VV 了_AS 一_CD 个_M 星期_NN 的_DEC 最后_JJ 一招_NN ”_PU 。_PU

2016年_NT 6月4日_NN ，_PU 在_P 第37_OD 届_M 世界业_NN 余围_NN 棋锦标赛_NN 新闻_VV 发_CD 布会_NN 上_LC ，_PU 国际围_NN 棋联盟_NN 事务_NN 总长杨俊_NN 安透露_NN 今年内_NN AlphaGo_NN 或将_NN 挑战中_NN 国职_NN 业棋_NN 士柯洁_NN 九_OD 段_NN 。_PU 不_AD 过_VV DeepMind_NN 创办人杰_NN 米斯_NN ·_PU 哈萨_NN 比斯_NN 表示_VV 目前还_NN 没有_VV 确定_VV AlphaGo_NN 的_DEG 下_DT 一_CD 步计划_NN ，_PU 一旦_CS 有明确_NN 的_DEC 安排_NN ，_PU 会有_VE 官方_NN 声明_NN 。_PU

2016年_NT 12月_NT 8日_NT ，_PU 第21届三_NR 星车_NN 险盃_NN 世界_NN 圍棋大_NN 师賽_NN 決賽過後_NN ，_PU 柯洁_NN 九_OD 段_NN 表示_VV ：_PU 「_PU 目前棋手_NN 之間_VV 的_DEC 比賽眾_NN 多_VA ，_PU 我放棄了_NN 與_P DeepZenGo_NR 的_DEC 對局_NN 。_PU 我覺得_NN ，_PU 我現在的_VV 狀_CD 態還_NN 不_AD 能_VV 打敗_VV 『_PU 阿爾法_NN 狗_NN 』_PU （_PU AlphaGo_NN ）_PU ，_PU 今後需要_NN 更加_VV 努力_NN 。_PU 」_PU

2017年_NT 4月10_NN 日_NN ，_PU 中国_NR 围棋_NN 协_AD 会_VA 、_PU Google_NN 和浙_NN 江省_NN 体育_NN 局联合在_NN 中国_NR 棋院召_NN 开新_VV 闻发布_NR 会_ETC ，_PU 宣布_NN 以柯洁_NN 为首_VV 的_DEC 中国_NN 棋手将_NN 和_P AlphaGo_NN 在_P 5月23_CD 至_AD 27_CD 日_NN 的_DEC 中国乌_NR 镇围棋_NN 峰_ETC 会_NN 上_NN 对弈_NN 。_PU 此_NN 次_NN 对弈分_NN 为_VC 三_NN 场_NN 比赛_NN ，_PU 首先_AD 在_VV 5月23_CD 、_PU 25_CD 和_CC 27_CD 日这三天_M ，_PU 柯洁将_NN 与_P AlphaGo_NN 下_NN 三_CC 番_NN 棋_LC ，_PU 用时_NN 为_VV 每_NN 方_AD 3_CD 小时_M ，_PU 5_OD 次_NN 1_OD 分钟_M 读秒_NN 。_PU GoogleDeepMind_NN 为本次_NN 柯洁与_NN AlphaGo_NN 的_DEC 三局比赛_NN 提供_VV 了_AS 150万_CD 美元_NN 的_DEC 胜者_NN 奖金_NN ，_PU 同时柯_NN 洁有_VV 30万_CD 美元_NN 的_DEC 出场费_NN 。_PU 此外_NT 在_P 5月26日_NT ，_PU 时越_NR 、_PU 芈昱廷_NR 、_PU 唐韦星_NR 、_PU 陈耀烨_NN 和_P 周睿羊_NN 5_CD 人_NN 将_BA 进行_VV 团队赛_NN ，_PU 他_CS 们将_NN 联合与_NN AlphaGo_NN 对弈_NN ，_PU 用时_NN 为_VC 每方_NN 2_CD 小时_NN 30_CD 分钟_M ，_PU 3_OD 次_CC 1分_CD 钟_CD 读秒_NN 。_PU 同日_NN ，_PU 古力_NN 、_PU 连笑_NN 还将_NN 和_NN AlphaGo_NN 合_AD 作_VV 进行_VV 人机_NN 配_NN 对赛_NN ，_PU 比赛将_NN 以棋手_NN 与_P AlphaGo_NN 合作_VV 的_DEC 形式_NN 进行_VV ，_PU 用时_NN 为_VC 每方_NN 1_CD 小时_VV ，_PU 1_OD 次_NN 1_OD 分钟_M 读秒_NN 。_PU 最_AD 终_VA ，_PU AlphaGo_NN 以_NN 3_OD ：_PU 0_OD 战_M 胜柯洁_NN ，_PU 并_AD 被_P 中国围_NR 棋协_NN 会_VV 授予_VV 职业围棋_NR 九_OD 段称号_NR ，_PU 不过聂卫_NR 平_NN 九_OD 段_M 称它_NN 的_DEC 水_NN 平_NN “_PU 至少_AD 20_CD 段_NN ”_PU 。_PU 在_P 结束_NN 与_P 柯洁_NN 的_DEC 比赛后_NN ，_PU Deepmind_NN 宣布_NN AlphaGo_NN 将_BA “_PU 退役_NN ”_PU ，_PU 不再_NN 参加_VV 任_NN 何围_NN 棋比赛_NN ，_PU 但将_NN 公开_VV AlphaGo_NN 自己与_NN 自己互弈_NN 的_DEC 棋谱_NN ；_PU 而_MSP 在_VV 未_NN 来_VV Deepmind_NN 将_BA 会把_NN AlphaGo_NN 的_DEC 技术_NN 运用到_NN 医疗_NN 等更_NN 广泛_VA 的_DEC 领域_NN 。_PU

AlphaGo_NN 的_DEC 团_NN 队于_VV 2017年_CD 10月_NT 19日在_NT 《_PU 自然_NN 》_PU 杂志_NN 上_NN 发表_VV 了_AS 一_CD 篇_M 文_NN 章_LC ，_PU 介绍_VV 了_AS AlphaGoZero_NN ，_PU 这_NN 是_VC 一_CD 个_M 没有_VV 用到_VV 人_NN 类_NN 数据_NN 的_DEC 版本_NN ，_PU 比以_NN 前任何_NN 击败人_NN 类_NN 的_DEG 版本都_NN 要_VV 强_AD 大_VA 。_PU 通过_P 跟自己对战_NN ，_PU AlphaGoZero_NR 经过_NN 3天_NT 的_DEG 学习_NN ，_PU 以_MSP 100_CD :_PU 0_CD 的_DEG 成绩_NN 超越_VV 了_AS AlphaGoLee_NN 的_DEG 实力_NN ，_PU 21_CD 天后_M 达到_VV 了_AS AlphaGoMaster_NR 的_DEC 水平_NR ，_PU 并在40天内_NR 超过_VV 了_AS 所有_DT 之前_NN 的_DEC 版本_NN 。_PU

2015年_NT 10月_NT 前后_NT 的_DEG 测试_NN 中_LC ，_PU AlphaGo_NN 多_NN 次_VC 使用不_NN 同数_NN 目的_NN CPU_NN 和_NN GPU_NN ，_PU 以单机_NN 或_NN 分布式_JJ 模式_NN 运行_NN 。_PU 每_DT 一_CD 步棋有_NN 两_CD 秒_NN 的_DEG 思考_NN 时间_NN 。_PU 最终_JJ Elo_NN 等级_JJ 分如下_NN 表_NN ：_PU

然而_NN AlphaGo_NN 的_DEC 棋力不_NN 断_AD 且_AD 显著_VA 地_DEV 增长_VV 。_PU 因此上表并_VV 不_AD 能_VV 代表_VV AlphaGo_NN 其他_NN 版本_NN 的_DEG 棋力_NN 。_PU

而_AD 在_P AlphaGoZero_NR 发布_NN 之后_LC ，_PU Deepmind_NN 表_NN 示新_VV 的_DEC 算法令_NN 新版_VV 的_DEC AlphaGo_NN 比旧版_NN 的_DEC 耗能量_NN 大幅_AD 下降_VV 10000_CD 至_CD 40000_CD TDP_M ，_PU 效能_NN 大幅_AD 提升_VV 。_PU

在_P 2016年_CD 1月_NT 27日_NT ，_PU ResearchatGoogle_NR 發布_VV 了_AS 有關新版_JJ AlphaGo_NN 跟其他_NN 圍棋_NN 軟件_NN ，_PU 以及樊麾_NN 二_AD 段_VA 的_DEC 對比如下_NN ：_PU
在_P 2017年_CD 5月_NT 24日_NT ，_PU DeepMind_NN 团队证_NN 实了在乌_NN 镇围棋_NN 峰_NN 会_NN 上_LC ，_PU 所_CS 使用_VV 的_DEC AlphaGo_NN 版本是_NN Master_NN ，_PU 并_AD 公布_VV 了_AS AlphaGo_NN 曾经_NN 公开_VV 对弈过_NN 的_DEC 版本_NN 以及_NN 和其_NN 他围棋_NN 软件_NN 比较_NN 的_DEC 图表_NN 。_PU 其中_NN ，_PU 新版_VV 的_DEC AlphaGoMaster_NR 能让_NN AlphaGoLee_NN （_PU 跟李_NN 世乭_NN 对战_NN 的_DEC 版本_NN ）_PU 三子_NN 。_PU 两_CD 个_M 版本_NN 的_DEG AlphaGo_NN 自我_NN 生成_VV 的_DEC Elo_NN 等级_JJ 分分别_NN 在_VV 4750_CD 和_CC 3750_CD 分附近_M ，_PU 与_P 柯洁_NN 九_CD 段_NN 在_P 5_CD 月_NN 23_CD 日的_M 3620_CD 分_LC （_PU 非官_NN 方排名_NN 系统_NN 所_MSP 统计_VV 的_SP ）_PU 相_NN 差_NN 约_AD 130_CD 到_CC 1130_CD 分之多_M 。_PU 然而_AD ，_PU 职业棋士_NN 樊_NN 麾_VC 二_CD 段替_NN AlphaGo_NN 团队_NN 的_DEC 首席_NN 研究员_NN 澄清_NN ：_NN “_PU 当_NN AlphaGo_NN 与从未_NN 对弈过_NN 的_DEC 人类_JJ 棋手_NN 对局_VV 时_LC ，_PU 这样_PN 的_DEG 优势就_NN 不_AD 复_AD 存在_VV 了_AS ，_PU 尤其是柯_AD 洁_DEV 这样_VV 的_DEC 围棋大_NN 师_NN ，_PU 他_NN 可_AD 能_VV 帮助_VV 我们_PN 发现_VV AlphaGo_NN 未曾_NN 展露_VV 的_DEC 新弱点_NN ”_PU 。_PU

AlphaGo_NN 使用_NN 蒙特_NN 卡洛_NN 树搜索_NN （_PU ）_PU ，_PU 借助_NN 估值_NN 网络_NN （_PU valuenetwork_NR ）_PU 与_P 走棋_NN 网络_NN （_PU policynetwork_NR ）_PU 这_VV 两_CD 种_M 深度神_NN 经网络_NN ，_PU 通过_P 估值_NN 网络_NN 来评估_NN 大量_CD 选点_NN ，_PU 并通_NN 过走棋_NN 网络_NN 选择_NN 落点_NN 。_PU AlphaGo_NN 最初通过_JJ 模仿人_NN 类_NN 玩家_NN ，_PU 尝试_NN 匹配职_NN 业棋手_NN 的_DEC 过往棋局_NN ，_PU 其_NN 数据_NN 库_NN 中_NN 约含_NN 3000万_CD 步棋着_NN 。_PU 後_CD 來它_NN 达到_VV 了_AS 一定_JJ 的_DEG 熟练_NN 程度_NN ，_PU 它_CS 开始_NN 和_NN 自己对弈_NN 大量_CD 棋局_NN ，_PU 使用_NN 强_NN 化学习_NN 进一步_JJ 改善它_NN 。_PU 围_NN 棋无_NN 法_NN 仅_AD 通过_P 寻找最_NN 佳棋步来_NN 解决_VV ；_PU 游戏_VV 一_CD 盘平均_NN 约有_VV 150_CD 步_M ，_PU 每_DT 一_CD 步平均_NN 约有_VV 200_CD 种_M 可选的_JJ 下法_NN ，_PU 这意味_NN 着有_VV 太_CD 多_CD 需要_NN 解决_VV 的_DEC 可能性_NN 。_PU

围棋_NN 职业_NN 九_CD 段棋手_NN 金明完_NN 称_P AlphaGo_NN 在_NN 与_P 樊麾_NN 的_DEC 对战中_NN ，_PU 表_NN 现得_VV 「_PU 像人_NN 类_NN 一样_VA 」_PU 。_PU 棋局裁判_NN 托比_NN ·_PU 曼宁_NR 则认_NN 为_VC AlphaGo_NN 的_DEC 棋风_NN 「_PU 保守_NN 」_PU 。_PU

而李世乭_NN 在_P 中国乌_NR 镇围棋_NN 峰会_VV 后_CD 表示_VV ，_PU AlphaGo_NN 的_DEG 发挥非_NN 常_NN 稳定_VA ，_PU 表现_VV 完_NN 美_NN ，_PU 要_NN 想找_VV 到_P 战_NN 胜它_VV 的_DEC 机会_NN 不_AD 能_VV 过于_VV 稳妥_VA ，_PU “_PU 必须越乱_NN 越_AD 好_VA ，_PU 难点越多_NN 越_AD 好_VA ”_PU 。_PU 另_NN 外_LC ，_PU 柯洁在赛_VV 后_NN 复盘_NN 表示_VV ，_PU AlphaGo_NN 能够_VV 非常_VV 有效_JJ 率_NN 地利_NN 用场_NN 上_NN 的_DEC 棋子_NN ，_PU 所_MSP 走_VV 的_DEC 棋子_NN 都_NN 与场上_NN 的_DEC 棋子有_NN 连贯及_NN 配合_VV ，_PU 并对_VV 棋子_NN 的_DEC 厚薄有_NN 独到_VV 的_DEC 理解_VV ，_PU 能把一些人类_VV 认_CD 为厚_NN 的_DEC 棋子_NN 予以_NN 打击_NN 和歼灭_NN 。_PU

AlphaGo_NN 被誉为人_NN 工智能_NN 研究的_NN 一_CD 项_NN 标志性_NN 进展_VV ，_PU 在此之前_VV ，_PU 围棋_VV 一_CD 直_NN 是机器学_NN 习领域_NN 的_DEC 难题_NN ，_PU 甚_AD 至_VV 被认为是_NN 当_P 代_NN 技术_NN 力所_NN 不_AD 及_VA 的_DEC 范畴_NN 。_PU 樊麾战_NN 的_DEC 棋局裁_NN 判_NN 托比_NN ·_PU 曼宁_NN 和_NN 国际围_NN 棋联_VV 盟_AS 的_DEC 秘书长都_NN 认_AD 为_VC 将_BA 来围棋_NN 棋_NN 手_AD 会_VV 借助_VV 电脑_NN 来提升棋_NN 艺_NN ，_PU 从_NN 错_OD 误_NN 中学习_NN 。_PU

台灣大_NN 學電機_NN 系_NN 教授_NN -_NN {_PU 于_NN }_PU -_PU 天立認為_NN ，_PU Google_NN 能_VV 夠成_VV 功結合_NN 深度神_NN 經_NN 網路_NN 、_PU 加強式_JJ 學習_NN 和_NN 蒙地_NN 卡羅樹_NN 狀_NN 搜_OD 尋_NN 三_OD 種_NN 演算法_NN ，_PU 其成_NN 果值_NN 得喝采_NN 。_PU 他認為_NN 這種_NN 技術_NN 應該適_NN 用於_NN 一_CD 般_NN 連續性_NN 決策_NN 問題_NN 。_PU 因為_NN AlphaGo_NN 可以_VV 在_VV 眾多可行_NR 的_DEC 決策中_NN ，_PU 適當分配_NR 運算_NN 資源_NN 來探索此_NN 一_CD 決_NN 策所帶來_VV 的_DEC 好處及_NN 壞處_NN ，_PU 並且可_NN 從探_VV 索_NN 中回_NN 饋修_NN 正錯誤_NN 。_PU 不過_NN -{于_VV }_PU -_PU 也_AD 提到_VV ，_PU 即使_NN AlphaGo_NN 所_MSP 使用_VV 的_DEC 學習_NN 模型_NN 比較_NN 具有_VV 一_CD 般性_NN ，_PU 它_CS 離真正_NN 完全_AD 通用_VV 的_DEC 學習_NN 模型_NN 仍有_VV 一_CD 段距離_NN 。_PU





