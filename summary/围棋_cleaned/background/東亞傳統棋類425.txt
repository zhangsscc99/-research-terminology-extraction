计算机围棋

计算机围棋是人工智能（AI）的一个领域，该领域致力于开发出可以下围棋的电脑程式。围棋是棋盘游戏的一种，有很古老的历史。

最先電腦圍棋也試圖用類似處理西洋棋的演算法——alpha-beta 剪枝法，即一般認為的暴力搜尋法，但成長非常慢。1986年，應昌期懸賞100萬美金，徵求可以打敗人類的圍棋軟體，並以15年為期限，但沒有任何人拿走獎金。到了20世紀末，這類程式表現最好的是陳志行製作的手談，其宣稱可以接近業餘初段，至少與低段職業差距9子以上，其他如GNU Go更是只有業餘5~10級左右。

代表：

Crazy Stone首次引進了蒙地卡羅搜尋樹，其原理是用蒙地卡羅法快速的把棋局下至終局，然後藉此判斷局勢，用這個方法，電腦圍棋得到飛快性的成長，並突破了業餘初段的壁障。這時代表現最好的是Zen，在AlphaGo出現的前一年，Zen的平行運算版本可以達到與職業棋士差距3~4子的水平。

這時期開始，開始出現了UEC杯等電腦圍棋比賽。在其中發生一個插曲，2010年時，黃士傑的Erica在2010電腦奧林匹亞獲得19路圍棋的冠軍，隔年又在UEC盃拿下亞軍，這在當時引起許多注目，因為Erica是單機程式，而其對手都是使用大型電腦，這也使得他獲得DeepMind公司的邀請。

代表程式：

深度學習原本主要應用是圖像分析，利用電腦模擬神經元，可以訓練電腦有類似人類「直覺」的反應，2014年左右，Google DeepMind和facebook等公司意識這可能可以用在處理電腦圍棋。最直接的想法是輸入人類的圍棋棋譜，並在程式中設定圍棋規則，以及各棋譜的最後勝負，利用監督學習讓電腦得到「棋感」，電腦因而可以給出特定局面下有哪些可能的行棋方法，後來這個方法在AlphaGo的論文中被稱為「走子網路」。2015年左右，DeepMind的David Silver意識到，其實圍棋的形勢判斷也可以交由神經網路決定，「價值網路」因此誕生。接著DeepMind團隊再使用強化學習——大眾媒體稱之為左右互搏——增強兩種神經網路，在大約三千萬盤的左右互搏後，超越了職業選手水平，這使得DeepMind最終贏得這項與facebook的競賽。

2016年1月27日，《自然》發表了Google DeepMind开发 AlphaGo 的論文，于2015年10月，在未讓子的挑戰中，以5:0戰績，擊敗歐洲圍棋冠軍——職業圍棋二段樊麾。這是電腦程式首次在公平比賽中擊敗職業棋手。2016年3月，AlphaGo在韓國首爾以4:1擊敗棋士李世乭。 2017年5月，AlphaGo在中国乌镇围棋峰会的三局比赛中以3:0击败当时世界排名第一的中国棋手柯洁。

代表程式：

圍棋給程式設計師們帶來了許多人工智能領域裡的挑戰。當如IBM深藍那樣的超級電腦，已經能夠擊敗世界上最好的西洋棋棋手的同時；卻有不少人能擊敗圍棋軟體。可見，要編寫出超越初級水平的電腦圍棋程式，是極其困難的一回事。

围棋的棋盘很大（19×19），因此通常被认为是难以编写围棋程序的一个重要原因。

与其它棋盘游戏相比，围棋的着法几乎不受规则限制。中国象棋第一步有42种选择，国际象棋有20种选择，但围棋有361种选择。有些着法较常见，有些几乎从未走过（例如第一步下在边线上），但所有着法都有可能。

象棋（以及大部分棋盘游戏如西洋跳棋和双陆棋）棋局过程中，棋子数逐渐减少，使游戏简化。但是，围棋中每下一子，都可能有其戰略意義，使得單純分析戰術並不管用，会使局势变得更复杂。

第一個電腦圍棋競賽是由USENIX贊助，在1984年到1988年間舉行。

宏碁電腦公司與應昌棋圍棋基金會從1986年開始，聯合舉辦電腦圍棋競賽，獲得冠軍的程式，可以挑戰職業棋士，獲勝獎金美金一百萬元。有效期至2000年。









